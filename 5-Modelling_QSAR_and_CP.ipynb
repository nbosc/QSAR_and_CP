{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model training\n",
    "- ### To be more efficient, the model training run on our CPU cluster\n",
    "- ### For each target, 2 models are trained, QSAR and Mondrian CP. Both have the same test set\n",
    "- ### RF is used in all the cases with default parameters based on model optimisation performed previously\n",
    "- ### 100 models are trained for each case using different splits internally but equivalent considering the 2 approaches\n",
    "- ### The predictions of the test set are written as well as the mean values for the compounds are also gathered in a summary file.\n",
    "- ### Models are also exported\n",
    "\n",
    "#### Notebook meant to be exported as .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sys import argv\n",
    "\n",
    "import pickle\n",
    "import dill, joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import matthews_corrcoef as mcc, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from nonconformist.cp import IcpClassifier\n",
    "from nonconformist.nc import NcFactory\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_sets(dat, seed=1234):\n",
    "    \n",
    "    # the fingerprint has to be in a column nammed FP\n",
    "    x_fp = [x.fp for x in dat['FP']]\n",
    "\n",
    "    # gather the descriptors\n",
    "    # that was a bad idea to select the column using their position\n",
    "    x = np.column_stack((dat[['logp', 'mwt', 'hbd', 'hba', 'rtb', 'tpsa']], x_fp))\n",
    "    \n",
    "    # the activity variable (here active/inactive) has to be nammed activity_class\n",
    "    y = dat.activity_class\n",
    "    \n",
    "    # split in data into training and test set (80%/20%)\n",
    "    x_train, x_test, y_train, y_test, id_train, id_test = train_test_split(x, y, dat.index, test_size = 0.2, random_state = seed, stratify = y)\n",
    "    \n",
    "    return(x_train, x_test, y_train, y_test, id_train, id_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(dat_file, model, prediction, actual, id_test, model_type, method, outputfile, iteration):\n",
    "    \n",
    "    # Save the model for later\n",
    "    joblib.dump(model, outputfile + '_{}_{}_model_{}'.format(method, model_type, str(iteration)), compress=3)\n",
    "\n",
    "    # Save the probabilities for any other extra analysis\n",
    "    iteration_results = pd.DataFrame(np.vstack([dat_file.loc[id_test]['target_chemblid'], dat_file.loc[id_test]['usmiles'], prediction.T, actual]).T, columns=['target_chemblid', 'usmiles', 'p0', 'p1', 'real_value'])\n",
    "    iteration_results.to_csv(outputfile + '_{}_{}_model_proba_{}.csv'.format(method, model_type, str(iteration)),index=False)\n",
    "    \n",
    "    return(iteration_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling(dat_file, default_dir, outputfile, method, t):\n",
    "    \n",
    "    dat_file = pickle.load(open(dat_file, 'rb'))\n",
    "    dat_file['activity_class'] = np.where(dat_file['activity_class'] == 'active', 1, 0)\n",
    "\n",
    "    \n",
    "    if not os.path.exists(default_dir+'/'+t):\n",
    "        os.makedirs(default_dir+'/'+t)\n",
    "    \n",
    "    l_qsar, l_cp, l_cp2 = [], [], []\n",
    "    \n",
    "    for i in range(0,100):\n",
    "        \n",
    "        x_train, x_test, y_train, y_test, id_train, id_test = split_train_test_sets(dat_file, seed=i)\n",
    "        \n",
    "        # QSAR\n",
    "        \n",
    "        ## Train\n",
    "        model = RandomForestClassifier(n_estimators=300, max_depth=20, random_state=12345, class_weight='balanced')\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        ## Predict\n",
    "        pred = model.predict_proba(x_test)\n",
    "        \n",
    "        ## Export\n",
    "        df_iter_res = export(dat_file, model, pred, y_test, id_test, 'QSAR', method, outputfile, i)        \n",
    "        l_qsar.append(df_iter_res)        \n",
    "        \n",
    "        # Mondrian Conformal prediction\n",
    "        \n",
    "        ## 1- calibration set is taken from the training set, test set is the same than in QSAR\n",
    "        \n",
    "        x_real_train, x_cal, y_real_train, y_cal, id_real_train, id_cal = train_test_split(x_train, y_train, y_train.index, test_size = 0.3, random_state = i)\n",
    "        \n",
    "        nc = NcFactory.create_nc(model) # Create a default nonconformity function\n",
    "        icp = IcpClassifier(nc, condition=lambda x: x[1]) # Create a mondrian inductive conformal classifier\n",
    "        \n",
    "        # Fit the ICP using the proper training set\n",
    "        icp.fit(x_real_train, y_real_train.values)\n",
    "        # Calibrate the ICP using the calibration set\n",
    "        icp.calibrate(x_cal, y_cal.values)\n",
    "        # Produce predictions for the test set, with confidence 90%\n",
    "        pred = icp.predict(x_test)\n",
    "\n",
    "        # Clear the model caches before exporting the model\n",
    "        icp.nc_function.model.last_x = None\n",
    "        icp.nc_function.model.last_y = None\n",
    "        \n",
    "        ### Export\n",
    "        df_iter_res = export(dat_file, icp, pred, y_test, id_test, 'CP_same_test', method, outputfile, i)\n",
    "        l_cp.append(df_iter_res)\n",
    "        \n",
    "    \n",
    "    ## Calculate the average p-values(CP)/probabilities(QSAR)\n",
    "    \n",
    "    df_qsar_results = pd.concat(l_qsar)\n",
    "    ####numeric columns are parsed as non numerical when dataframe is created\n",
    "    df_qsar_results.p0 = df_qsar_results.p0.map(np.float64)\n",
    "    df_qsar_results.p1 = df_qsar_results.p1.map(np.float64)\n",
    "    df_qsar_results.real_value = df_qsar_results.real_value.map(np.int)\n",
    "    df_qsar_results_gp =  df_qsar_results.groupby(['target_chemblid', 'usmiles']).mean().reset_index()\n",
    "\n",
    "    df_qsar_results_gp.to_csv(outputfile + '_{}_{}_model_proba_mean_results.csv'.format(method, 'QSAR'),index=False)\n",
    "    \n",
    "    df_cp_results = pd.concat(l_cp)\n",
    "    ####numeric columns are parsed as non numerical when dataframe is created\n",
    "    df_cp_results.p0 = df_cp_results.p0.map(np.float64)\n",
    "    df_cp_results.p1 = df_cp_results.p1.map(np.float64)\n",
    "    df_cp_results.real_value = df_cp_results.real_value.map(np.int)\n",
    "    df_cp_results_gp =  df_cp_results.groupby(['target_chemblid', 'usmiles']).mean().reset_index()\n",
    "\n",
    "    df_cp_results_gp.to_csv(outputfile + '_{}_{}_model_proba_mean_results.csv'.format(method, 'CP_same_test'),index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    path, df_prot, default_dir, target, method = argv\n",
    "    \n",
    "    # subdirectory for target\n",
    "    if not os.path.exists(default_dir+'/'+target):\n",
    "        os.makedirs(default_dir+'/'+target)\n",
    "        \n",
    "    # result file\n",
    "    outputfile = '{}/{}/{}'.format(default_dir, target, target)\n",
    " \n",
    "    modelling(df_prot, default_dir, outputfile, method, target)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
